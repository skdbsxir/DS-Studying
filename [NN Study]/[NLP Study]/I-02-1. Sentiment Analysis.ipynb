{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감정 분석\n",
    "\n",
    "<br>\n",
    "\n",
    "- 파이프라인이 처리하는 어떤것이든 각 토큰에는 어떠한 정보가 담겨있음.\n",
    "- 단어의 감정(sentiment), 그 단어가 불러 일으키는 전반적인 느낌은 그런 정보의 중요한 일부분.\n",
    "- 감정분석은 NLP의 일반적인 응용 중 하나.\n",
    "    - 이를 응용해 스팸 필터링, 챗봇응용 등이 있음.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 파이프라인이 텍스트 조각에 담긴 감정을 분석해 수치화하려면 어떻게 해야 할까. 크게 2가지 접근방식.\n",
    "    1. 사람이 직접 작성한 **규칙 기반 알고리즘** 사용 $\\rightarrow$ **발견법(heuristics)에 기초한 감성 분석**\n",
    "        - 텍스트에서 **특정 키워드**를 찾고, **키워드 들에 부여된 수치 점수를 취합**.\n",
    "        - **특정 단어와 점수 쌍을 담은 Dict 자료구조**가 필요. 사람이 직접 만들어야 함.\n",
    "        - 주로 **VADER**를 이용.\n",
    "    2. 컴퓨터가 자료로부터 직접 배우는 **ML모형** 사용\n",
    "        - **분류명이 붙은** 문장/문서집합 을 통해 ML모형 훈련, 규칙 생성.\n",
    "        - ML모형은 입력 텍스트에 대한 수치적 감정 점수를 출력하도록 훈련.\n",
    "        - **'정답'에 해당하는 감정 점수가 부여된 텍스트 조각들로 이뤄진 대량의 자료가 필요**한 지도학습 모형.\n",
    "            - 주로 해시태그가 많이 붙는 tweet 데이터가 많이 쓰임.\n",
    "            - 또는 의견과 함께 별점 평가를 받아 활용할 수도 있음.\n",
    "        - **Naive-Bayes**라 불리는 토큰 기반 ML 알고리즘을 주로 이용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER : 규칙기반 감정분석기\n",
    "\n",
    "<br>\n",
    "\n",
    "- **V**alence **A**ware **D**ictionary for s**E**ntiment **R**easoning (감정 추론을 위한 결합가 인식 사전)의 약자.\n",
    "- NLTK의 경우 nltk.sentiment.vader 를 통해 사용 가능.\n",
    "- vaderSentiment 라는 패키지도 있음. 예제는 이걸 쓸것.\n",
    "\n",
    "        pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-11T07:38:30.902244Z",
     "start_time": "2021-08-11T07:38:26.291127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\skdbs\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skdbs\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\skdbs\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\skdbs\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\skdbs\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (4.0.0)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pype1 (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\users\\skdbs\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.2.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\skdbs\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:48:43.058612Z",
     "start_time": "2021-08-12T00:48:43.026393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"( '}{' )\", 1.6),\n",
       " (\"can't stand\", -2.0),\n",
       " ('fed up', -1.8),\n",
       " ('screwed up', -1.5)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "sa.lexicon # lexicon에 토큰-감정 점수 쌍들이 들어있음.\n",
    "\n",
    "# VADER는 이모티콘 사용. 분석이 잘 되려면 토큰 생성기가 문장 부호들을 제거하지 않는것이 바람직.\n",
    "sa.polarity_scores(text={\n",
    "    ':(' : -1.9,\n",
    "    ':)' : 2.0,\n",
    "    'pls' : 0.3,\n",
    "    'plz' : 0.3,\n",
    "    'great' : 3.1\n",
    "})\n",
    "[(tok, score) for tok, score in sa.lexicon.items() if \" \" in tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:48:44.831112Z",
     "start_time": "2021-08-12T00:48:44.825254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.661, 'pos': 0.339, 'compound': 0.6249}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"Python is very readable and it's great for NLP.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    VADER 알고리즘음 감정의 세기(intensity)를 긍정(pos), 부정(neg), 중립(neu)로 분류.\n",
    "    이 3개의 점수를 담은 하나의 복합 자료 구조를 return 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:48:45.932280Z",
     "start_time": "2021-08-12T00:48:45.927397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.737, 'pos': 0.263, 'compound': 0.431}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.polarity_scores(text=\"Python is not a bad choice for most applications.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    not 같은 부정어를 상당히 잘 처리함.\n",
    "    not bad의 긍정 점수는 great보다 약간만 낮을 정도로 높은 편.\n",
    "    VADER의 내장 토큰 생성기는 자신의 어휘집엔 없는 단어들을 모두 무시, n-gram은 전혀 고려 X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:49:38.084933Z",
     "start_time": "2021-08-12T00:49:38.079075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+0.9455: Absolutely perfect!! Love it! :-) :-) :-)\n",
      "-0.8768: Horrible! Completely useless :(\n",
      "-0.1531: It was OK. Some good and some bad things.\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"Absolutely perfect!! Love it! :-) :-) :-)\",\n",
    "          \"Horrible! Completely useless :(\",\n",
    "          \"It was OK. Some good and some bad things.\"]\n",
    "for doc in corpus:\n",
    "    scores = sa.polarity_scores(doc)\n",
    "    print('{:+}: {}'.format(scores['compound'], doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    상당히 잘 동작하고 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VADER의 유일한 단점은 **모든 단어가 아니라 약 7500개의 단어만을 고려**한다는 것.\n",
    "- 모든 단어로 감정 점수를 측정해야 한다면 할 일이 엄청나게 늘어남.\n",
    "    - 일일이 점수를 매기거나, lexicon 사전 자료 구조에 수많은 커스텀 단어를 추가해야 함.\n",
    "- ***규칙 기반 접근방식은 대상 자연어를 이해하지 못하면 거의 불가능***한 일.\n",
    "- 그래서 **기계학습에 기초한 감정 분석기를 사용**하는 것이 편리하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes Model\n",
    "\n",
    "<br>\n",
    "\n",
    "- 주어진 문서 집합에서 목표 변수를 예측하는 키워드들을 찾음.\n",
    "- 감정분석의 경우, 모형의 **목표 변수는 평가하고자 하는 감정**.\n",
    "    - 즉, 해당 **감정을 예측하는 단어들을 분류**.\n",
    "- 미리 만들어진 사전에 의존하지 않고, 임의의 문제에 대해 최선의 감정 점수를 찾아냄.\n",
    "- 마찬가지로 Train Set이 필요. 각 내용에 대한 분류명이 붙은 대량의 텍스트 문서가 필요.\n",
    "    - NLPIA에 이런 자료 집합이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-12T00:19:06.089Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nlpia # 데스크탑은 이미 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:49:47.648803Z",
     "start_time": "2021-08-12T00:49:41.803015Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\pugnlp\\constants.py:136: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  [datetime.datetime, pd.datetime, pd.Timestamp])\n",
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\pugnlp\\constants.py:158: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\pugnlp\\tutil.py:100: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\pugnlp\\util.py:80: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "INFO:nlpia.constants:Starting logger in nlpia.constants...\n",
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\nlpia\\futil.py:30: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\nlpia\\loaders.py:78: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  np = pd.np\n",
      "INFO:nlpia.loaders:No BIGDATA index found in C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\nlpia\\data\\bigdata_info.csv so copy C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\nlpia\\data\\bigdata_info.latest.csv to C:\\Users\\skdbs\\Anaconda3\\lib\\site-packages\\nlpia\\data\\bigdata_info.csv if you want to \"freeze\" it.\n",
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\skdbs\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\mavis-batey-greetings.csv',), **{'low_memory': False})`...\n",
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\skdbs\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\sms-spam.csv',), **{'low_memory': False})`...\n",
      "INFO:nlpia.futil:Reading CSV with `read_csv(*('C:\\\\Users\\\\skdbs\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\hutto_ICWSM_2014/movieReviewSnippets_GroundTruth.csv.gz',), **{'nrows': None, 'low_memory': False})`...\n",
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    sentiment                                               text\n",
       " id                                                              \n",
       " 1        2.27  The Rock is destined to be the 21st Century's ...\n",
       " 2        3.53  The gorgeously elaborate continuation of ''The...\n",
       " 3       -0.60                     Effective but too tepid biopic\n",
       " 4        1.47  If you sometimes like to go to the movies to h...\n",
       " 5        1.73  Emerges as something rare, an issue movie that...,\n",
       "        sentiment\n",
       " count   10605.00\n",
       " mean        0.00\n",
       " std         1.92\n",
       " min        -3.88\n",
       " 25%        -1.77\n",
       " 50%        -0.08\n",
       " 75%         1.83\n",
       " max         3.94)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpia.data.loaders import get_data\n",
    "\n",
    "movies = get_data('hutto_movies')\n",
    "movies.head().round(2), movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    describe로 본 결과, 영화 평점은 -4 ~ +4 사이인 것으로 보임.\n",
    "  \n",
    "  \n",
    "<br>\n",
    "\n",
    "- 이 영화평 텍스트들을 토큰화 해 단어 모음을 생성해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T01:00:47.244138Z",
     "start_time": "2021-08-12T01:00:47.239257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 75) # DF내용을 좀더 보기좋게 row 너비 늘림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T01:02:00.023975Z",
     "start_time": "2021-08-12T01:00:48.965624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10605, 20756)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destined</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>the</th>\n",
       "      <th>21st</th>\n",
       "      <th>Century's</th>\n",
       "      <th>new</th>\n",
       "      <th>...</th>\n",
       "      <th>Ill</th>\n",
       "      <th>slummer</th>\n",
       "      <th>Rashomon</th>\n",
       "      <th>dipsticks</th>\n",
       "      <th>Bearable</th>\n",
       "      <th>Staggeringly</th>\n",
       "      <th>’</th>\n",
       "      <th>ve</th>\n",
       "      <th>muttering</th>\n",
       "      <th>dissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20756 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  Ill  \\\n",
       "0    1     1   1         1   2   1    1     1          1    1  ...    0   \n",
       "1    2     0   1         0   0   0    1     0          0    0  ...    0   \n",
       "2    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "3    0     0   1         0   4   0    1     0          0    0  ...    0   \n",
       "4    0     0   0         0   0   0    0     0          0    0  ...    0   \n",
       "\n",
       "   slummer  Rashomon  dipsticks  Bearable  Staggeringly  ’  ve  \\\n",
       "0        0         0          0         0             0  0   0   \n",
       "1        0         0          0         0             0  0   0   \n",
       "2        0         0          0         0             0  0   0   \n",
       "3        0         0          0         0             0  0   0   \n",
       "4        0         0          0         0             0  0   0   \n",
       "\n",
       "   muttering  dissing  \n",
       "0          0        0  \n",
       "1          0        0  \n",
       "2          0        0  \n",
       "3          0        0  \n",
       "4          0        0  \n",
       "\n",
       "[5 rows x 20756 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import casual_tokenize # 이모지, 비표준적인 부호, 비속어를 좀더 잘 처리함.\n",
    "from collections import Counter\n",
    "\n",
    "bags_of_words = []\n",
    "for text in movies.text:\n",
    "    # text를 토큰화 한 내용들의 수를 세고, Dict로 담아 전달\n",
    "    bags_of_words.append(Counter(casual_tokenize(text)))\n",
    "\n",
    "# Dict를 받아 모든 key-value로 하나의 테이블을 생성.\n",
    "# Key는 Column이 되고, key가 없다면 해당 테이블 칸은 NaN이 됨.\n",
    "# 그러므로 이런 결측값들을 0으로 채우는 것이 좋을 것.\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "print(df_bows.shape)\n",
    "df_bows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    생각한 것 보다 큼.\n",
    "    왜? 불용어 처리도 안했고, 어간/표제어 추출도 안했으니까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T01:02:21.988164Z",
     "start_time": "2021-08-12T01:02:21.969613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>The</th>\n",
       "      <th>Rock</th>\n",
       "      <th>is</th>\n",
       "      <th>destined</th>\n",
       "      <th>to</th>\n",
       "      <th>be</th>\n",
       "      <th>the</th>\n",
       "      <th>21st</th>\n",
       "      <th>Century's</th>\n",
       "      <th>new</th>\n",
       "      <th>...</th>\n",
       "      <th>Schwarzenegger</th>\n",
       "      <th>,</th>\n",
       "      <th>Jean</th>\n",
       "      <th>Claud</th>\n",
       "      <th>Van</th>\n",
       "      <th>Damme</th>\n",
       "      <th>or</th>\n",
       "      <th>Steven</th>\n",
       "      <th>Segal</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   The  Rock  is  destined  to  be  the  21st  Century's  new  ...  \\\n",
       "0    1     1   1         1   2   1    1     1          1    1  ...   \n",
       "1    2     0   1         0   0   0    1     0          0    0  ...   \n",
       "2    0     0   0         0   0   0    0     0          0    0  ...   \n",
       "3    0     0   1         0   4   0    1     0          0    0  ...   \n",
       "4    0     0   0         0   0   0    0     0          0    0  ...   \n",
       "\n",
       "   Schwarzenegger  ,  Jean  Claud  Van  Damme  or  Steven  Segal  .  \n",
       "0               1  1     1      1    1      1   1       1      1  1  \n",
       "1               0  0     0      0    0      0   0       0      0  4  \n",
       "2               0  0     0      0    0      0   0       0      0  0  \n",
       "3               0  1     0      0    0      0   0       0      0  1  \n",
       "4               0  1     0      0    0      0   0       0      0  1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bows.head()[list(bags_of_words[0].keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    아주 간단하게 나이브-베이즈 모형을 통해 감정 분석을 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T00:45:32.085195Z",
     "start_time": "2021-08-12T00:45:32.079337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T02:12:43.654248Z",
     "start_time": "2021-08-12T02:12:39.286757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>sentiment_ispositive</th>\n",
       "      <th>predicted_ispositive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.266667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.533333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.466667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.733333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.533333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.266667</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  predicted_sentiment  sentiment_ispositive  \\\n",
       "id                                                         \n",
       "1    2.266667                    4                     1   \n",
       "2    3.533333                    4                     1   \n",
       "3   -0.600000                   -4                     0   \n",
       "4    1.466667                    4                     1   \n",
       "5    1.733333                    4                     1   \n",
       "6    2.533333                    4                     1   \n",
       "7    2.466667                    4                     1   \n",
       "8    1.266667                   -4                     1   \n",
       "\n",
       "    predicted_ispositive  \n",
       "id                        \n",
       "1                      1  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      1  \n",
       "5                      1  \n",
       "6                      1  \n",
       "7                      1  \n",
       "8                      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # 결과는 여러개이니 다항분포 모형 사용.\n",
    "\n",
    "nb = MultinomialNB()\n",
    "# train\n",
    "nb = nb.fit(df_bows, movies.sentiment > 0)\n",
    "movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4\n",
    "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs() # 오차값 계산\n",
    "# movies.error.mean().round(1)\n",
    "movies['sentiment_ispositive'] = (movies.sentiment > 0).astype(int)\n",
    "movies['predicted_ispositive'] = (movies.predicted_sentiment > 0).astype(int)\n",
    "movies[\"\"\"sentiment predicted_sentiment sentiment_ispositive predicted_ispositive\"\"\".split()].head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    왜 컬럼추가가 안되는걸까\n",
    "    predict_proba 말고 predict..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T04:28:08.254813Z",
     "start_time": "2021-08-12T04:28:08.246818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344648750589345"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    긍정적 추천 평가는 93%의 경우 정확함을 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VADER 접근방식이라면 몇천개의 단어를 고르고, 각각에 감정 점수를 매겨야 했을 것.\n",
    "- 분류명이 붙은 텍스트만을 이용해 ML모델을 굴리니 괜찮게 분류했다.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 영화 평점이 아닌 상품평 같은 완전히 다른 종류의 감정 점수를 예측하게 되면 어떻게 될까?\n",
    "- 앞선 영화 분류는 추천/비추천 중 하나로 분류하도록 훈련했음.\n",
    "- 상품평에 적용하면 어떤 결과가 나올까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    잔에러 너무많이나서 시간 너무버림. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나이브 베이즈 모형은 VADER보다 부정어를 잘 다루지 못함.\n",
    "    - **부정어와 그것이 수식하는 단어를 n-gram으로 묶어서 토큰화** 해야 함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
