{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서 Chapter 02. 에서 토큰을 추출해 빈도를 세고 분류하는 방법을 살펴봤음.\n",
    "- 이런 토큰들로 다른 일을 해보자.\n",
    "    - **주어진 단어가 특정 문서 or 말뭉치 전체에서 얼마나 중요한지 측정**해보자. 단어의 중요도 Check.\n",
    "    - 긍정성 점수나 분류명이 있다면 그런 **단어들이 등장한 횟수를 나머지 모든 문서와 비교해 점수를 매겨**보자.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 앞서 얻었었던 이진 비트 벡터 형태로 표현하는 것이 아닌, **의미가 있는 연속된 값**들로 바꿔보자.\n",
    "    - 단어들이 이제 이산 공간이 아닌 **연속 공간에서 표현**.\n",
    "    - 뭐가 좋나? **좀 더 다양한 수학 도구들을 이용해 단어 표현을 다룰 수 있음**.\n",
    "    - 최종 목표는 **단어의 중요도 or 단어의 정보 내용을 반영한 수치 표현을 찾는 것**.\n",
    "        - 이번 장에선 **단어의 중요도를 반영하는 수치 표현**을 자세히 볼 것.\n",
    "        - Chapter 04. 에서는 수치로 표현한 단어 정보를 가지고 단어의 의미를 수량화 할 것.\n",
    "\n",
    "<br>\n",
    "\n",
    "용어 하나 짚고 넘어가자.  <br>\n",
    "**TF-IDF 벡터** : 단어의 중요도를 좀 더 잘 표현하는 단어 점수 벡터.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 빈도(도수)에 기초한다는 점에서 **통계적 모형**에 해당."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 모음\n",
    "\n",
    "<br>\n",
    "\n",
    "- 앞서 텍스트들을 통해 간단한 벡터 공간 모형을 만들었음.\n",
    "    - one-hot 같은 방법을 통해 이진 단어 모음(bag of words)을 만들고,\n",
    "    - 이 벡터를 DataFrame에 담아 문서 검색을 위한 index를 만들었음.\n",
    "- 단어 출현 횟수가 어떻게 도움이 되는지 예제를 한번 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T04:54:15.074840Z",
     "start_time": "2021-08-12T04:54:15.056850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'faster', 'harry', 'got', 'to', 'the', 'store', ',', 'the', 'faster', 'harry', ',', 'the', 'faster', ',', 'would', 'get', 'home', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'the': 4,\n",
       "         'faster': 3,\n",
       "         'harry': 2,\n",
       "         'got': 1,\n",
       "         'to': 1,\n",
       "         'store': 1,\n",
       "         ',': 3,\n",
       "         'would': 1,\n",
       "         'get': 1,\n",
       "         'home': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from collections import Counter # Counter 같은걸 bag or multiset 자료구조 라 부르기도 함.\n",
    "\n",
    "sentence = \"\"\"The faster Harry got to the store, the faster Harry, the faster, would get home.\"\"\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(sentence.lower())\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "bag_of_words = Counter(tokens)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dict형태라 순서가 좀 뒤죽박죽.\n",
    "    key 순서는 단순히 저장, 갱신, 조회에 최적화. 일관된 출력 고려X.\n",
    "    그래서 기존 문장에 있던 단어 순서정보는 사라짐.\n",
    "    \n",
    "    빈도수 정렬을 위한 most_common이라는 메서드가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-12T04:56:32.595700Z",
     "start_time": "2021-08-12T04:56:32.586720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4), ('faster', 3), (',', 3), ('harry', 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.most_common(4) # 가장 많이 출현한 4개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
