{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "322797de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:49:51.106828Z",
     "start_time": "2021-09-05T23:49:51.090868Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a4081a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:00:49.471235Z",
     "start_time": "2021-09-06T00:00:49.448259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['네이버쇼핑_(단호박_다이어트식품)_cleaned.csv',\n",
       "  '네이버쇼핑_(단호박_샐러드)_cleaned.csv',\n",
       "  '네이버쇼핑_(단호박칩_반려동물)_cleaned.csv',\n",
       "  '스마트스토어_(구운_단호박)_cleaned.csv',\n",
       "  '스마트스토어_(다이어트_스낵)_cleaned.csv',\n",
       "  '스마트스토어_(호박_스낵)_cleaned.csv'],\n",
       " [])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'UseData/Voucher/Cleaned/'\n",
    "csvUrl = 'UseData/Voucher/WordExtract/'\n",
    "os.listdir(url), os.listdir(csvUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d430b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-05T23:49:55.697525Z",
     "start_time": "2021-09-05T23:49:55.673406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>네이버쇼핑_(단호박_다이어트식품)_cleaned.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버쇼핑_(단호박_샐러드)_cleaned.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>네이버쇼핑_(단호박칩_반려동물)_cleaned.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>스마트스토어_(구운_단호박)_cleaned.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스마트스토어_(다이어트_스낵)_cleaned.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스마트스토어_(호박_스낵)_cleaned.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             File\n",
       "0  네이버쇼핑_(단호박_다이어트식품)_cleaned.csv\n",
       "1     네이버쇼핑_(단호박_샐러드)_cleaned.csv\n",
       "2   네이버쇼핑_(단호박칩_반려동물)_cleaned.csv\n",
       "3     스마트스토어_(구운_단호박)_cleaned.csv\n",
       "4    스마트스토어_(다이어트_스낵)_cleaned.csv\n",
       "5      스마트스토어_(호박_스낵)_cleaned.csv"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어짜피 내용이 똑같아서 굳이 나눌 필요가 없을거같은데\n",
    "filesDF = pd.DataFrame({'File' : os.listdir(url)})\n",
    "filesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81fe19",
   "metadata": {},
   "source": [
    "    긍/부정 별 키워드 csv 파일 생성 함수\n",
    "        -> JJS Tokenizing 04 참고."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f3d521e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:05:25.026301Z",
     "start_time": "2021-09-06T00:05:25.016264Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단어 추출\n",
    "def WordSelector(series):\n",
    "    wordList = []\n",
    "    for index in range(len(series)):\n",
    "        for word, pos in series[index]:\n",
    "            if (pos == 'Noun') or (pos == 'Adjective'):\n",
    "                wordList.append(word)\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d93c8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:05:46.350371Z",
     "start_time": "2021-09-06T00:05:46.319641Z"
    }
   },
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def CSVMaker(url, file):\n",
    "    df = pd.read_csv(url + file, index_col=0) # 파일 1개씩 읽어와서\n",
    "    df.drop('제목', axis=1, inplace=True) # '제목' 컬럼은 사용 X.\n",
    "    \n",
    "    # 형태소 분리 및 태깅작업 먼저 진행\n",
    "    df['Contents'] = df['Contents'].apply(lambda x: okt.pos(x, norm=True, stem=True))\n",
    "    \n",
    "    # 긍/부정 프레임 나누기\n",
    "    df_pos = df.loc[df['긍부정']==1].reset_index()\n",
    "    df_pos.drop('index', axis=1, inplace=True)\n",
    "    df_neg = df.loc[df['긍부정']==0].reset_index()\n",
    "    df_neg.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    # 긍/부정 별로 데이터 프레임 생성\n",
    "    # 긍정은 500개 정도? 부정은 전부. (부정이 갯수가 더 적으니까.)\n",
    "    wordPosList = Counter(WordSelector(df_pos['Contents'])).most_common(500)\n",
    "    wordPosDF = pd.DataFrame(wordPosList)\n",
    "    wordPosDF.columns = wordPosDF.columns.astype(str)\n",
    "    wordPosDF = wordPosDF.rename(columns={'0':'word', '1':'freq'})\n",
    "    \n",
    "    wordNegList = Counter(WordSelector(df_neg['Contents'])).most_common()\n",
    "    wordNegDF = pd.DataFrame(wordNegList)\n",
    "    wordNegDF.columns = wordNegDF.columns.astype(str)\n",
    "    wordNegDF = wordNegDF.rename(columns={'0':'word', '1':'freq'})\n",
    "    \n",
    "    # CSV파일로 저장\n",
    "    wordPosDF.to_csv(csvUrl + file[:-4] + '_keyword_pos.csv', index=True, header=True, encoding='utf-8-sig')\n",
    "    wordNegDF.to_csv(csvUrl + file[:-4] + '_keyword_neg.csv', index=True, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c571ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:05:50.958999Z",
     "start_time": "2021-09-06T00:05:47.447738Z"
    }
   },
   "outputs": [],
   "source": [
    "file = filesDF['File'][0]\n",
    "CSVMaker(url, file) # 만들어지는건 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "316f5794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:08:28.113934Z",
     "start_time": "2021-09-06T00:07:57.952670Z"
    }
   },
   "outputs": [],
   "source": [
    "for index in range(len(filesDF)):\n",
    "    file = filesDF['File'][index]\n",
    "    CSVMaker(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547055d",
   "metadata": {},
   "source": [
    "    긍/부정 나눈거 말고도 그냥 통합본을 하나 만들까\n",
    "    키워드 한 500개 정도만 뽑아서?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08d7286c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:18:25.747277Z",
     "start_time": "2021-09-06T00:18:25.727331Z"
    }
   },
   "outputs": [],
   "source": [
    "def TotalCSVMaker(url, file):\n",
    "    df = pd.read_csv(url + file, index_col=0) # 파일 1개씩 읽어와서\n",
    "    df.drop('제목', axis=1, inplace=True) # '제목' 컬럼은 사용 X.\n",
    "    \n",
    "    # 형태소 분리 및 태깅작업 먼저 진행\n",
    "    df['Contents'] = df['Contents'].apply(lambda x: okt.pos(x, norm=True, stem=True))\n",
    "    wordList = Counter(WordSelector(df['Contents'])).most_common(500)\n",
    "    wordDF = pd.DataFrame(wordList)\n",
    "    wordDF.columns = wordDF.columns.astype(str)\n",
    "    wordDF = wordDF.rename(columns={'0':'word', '1':'freq'})\n",
    "    \n",
    "    wordDF.to_csv(csvUrl + file[:-4] + '_keyword_total.csv', index=True, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "955ce9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-06T00:18:56.573046Z",
     "start_time": "2021-09-06T00:18:26.910111Z"
    }
   },
   "outputs": [],
   "source": [
    "for index in range(len(filesDF)):\n",
    "    file = filesDF['File'][index]\n",
    "    TotalCSVMaker(url, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdda59c",
   "metadata": {},
   "source": [
    "    단어-빈도 CSV 만들었고 이제\n",
    "    \n",
    "    1. WordCloud 그려보고\n",
    "    2. Word2Vec 돌려서 -> '단호박'처럼 특정 키워드 넣고 연관된 단어가 뭐 나오는지 확인?\n",
    "    3. LDA 돌려보기\n",
    "        ----- 2,3번은 모두 토큰화 진행된 단어들로 해야함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'[WorkBase]'",
   "language": "python",
   "name": "workbase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
