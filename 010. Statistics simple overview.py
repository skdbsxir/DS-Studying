# 데이터 과학에서 통계를 사용하지만, 통계학자들이 접근하는 것 처럼 상세히 따지지는 않는다. 왤까?
 ## 일반적으로 다루는 데이터 양들이 많기 때문에.
 ## 하지만, 의학 데이터 같은 경우엔 데이터 양 보단 데이터 자체의 중요도가 높음.
  ### 통계적 가정이 많이 필요하고, 패턴을 알아내는 과정이 일반적인 다른 데이터보다 좀 난해하긴 하다.

"""
# 가설검정 : 데이터가 많지 않아서 현상을 수비게 단정 지을 수 없을때, 통계적 지식으로 이를 이해하는 과정.

ex) 동전을 던졌을 때 앞면이 9번, 뒷면이 1번 나왔다면 이 동전은 공정한 동전일까? (가설 - 이 동전은 편향된 동전이다.)
 이 데이터만을 가지고 가설을 판단하는것은 불가능. 정확한 추정을 위해선 '선험적 확률(prior probabilty, 일반적으로 동전이 편향되어 있을 확률)'을 알아야 함.
 통계학적으로 정확한 질문은 '이 동전이 편향된 동전이라면, 주어진 데이터가 나올 확률이 얼마나 되는가?'이 된다.
 공정한 동전이라 가정하고 확률을 계산해보자. (이항분포가 아닌 직관적으로)
  > 동전은 앞/뒤 가 있고, 이를 10번 던지면 모든 경우의 수는 2^10 = 1024, 이들이 발생할 확률은 동일.
  > 그러면 10번중 9번 앞면이 나오는 편향된 결과는 몇 번이 있을까?
   >> 10번 모두 앞면이 나오는 경우의 수는 1가지.
   >> 앞면이 9번 나오는 경우의 수 == 10번중 1번만 뒷면이 나오는 경우의 수. 총 10가지.
   >> 10번 모두 뒷면이 나오는 경우의 수는 1가지.
   >> 뒷면이 9번 나오는 경우의 수는 총 10가지.
  > 총 22가지. 22 / 1024 = 0.0215이므로 공정한 동전이라 볼 수있음.
  > 즉, 주어진 데이터만큼 결과가 편황될 확률은 2%밖에 되지 않는다.

우리가 처음에 '이 동전은 편향된 동전이다(이 동전은 공정한 동전이 아니다)'라고 세운 가설을 [귀무가설] 이라 한다. 
 (통계분석을 위해 세우는 가설 중 패턴이나 사건이 존재하지 않는다고 가정하는 가설. 우리가 결과만 보고 주장하는 가설.)
 > 분석의 목표는 귀무가설이 거짓이라는 것을 증명함으로써 특정 패턴을 찾아내는 것.

중간에 계산한 '앞면의 횟수'가 [검정 통계량]이 된다. 이는 데이터에 나타난 패턴을 요약하는 값. 귀무가설에 기반한 검정통계량의 분포를 계산하면 귀무가설을 검정할 수 있다.
우리가 계산한 확률(2%)이 [p-value]. 이는 데이터에 나타난 검정통계량이 얼마나 낮은 확률을 가지는지 조사하는 값.
 > 귀무 가설은 패턴이 존재하지 않는 것을 가정한 가설. 검정 통계량이 낮은 확률을 가질수록 귀무가설은 설득력을 잃게 된다.
  >> 즉, p-value가 많이 낮아질수록 귀무가설을 지지할 이유가 없어진다는 의미.
 > 보통 0.05를 유의수준으로 설정하지만, 주어진 데이터 개수와 패턴의 선험적 확률, p-value에 따라 상황을 정확하게 이해해 적절한 유의수준을 적용하는 것이 중요.
 
다중 가설검정에서 1종 오류(귀무가설이 참인데 이를 기각하는 경우)를 범할 확률을 보정하기 위해,
여러개의 가설들에 대해 최소한 하나의 1종오류가 발생할 가능성을 계산해 보정하는 '본페로니 보정(수정)법'을 사용하기도 한다. 그냥 참고.
"""

# t-test : 두 모집단의 평균 비교. 독립/대응/일표본. 2가지의 귀무가설이 존재.
 ## 두 데이터는 같은 분포의 표본이다.
 ## 두 데이터는 평균은 같지만 분산이 다른 두 분포의 표본이다.
# scipy.stats 모듈의 ttest_ind 를 통해 독립t-test를 수행할 수 있음.
# return 값은 t값과 p-value. 인자로 equal_var=False를 통해 등분산성을 만족하지 않는 경우도 계산이 가능함.
from scipy.stats import ttest_ind

t_score, p_value = ttest_ind([1,2,3,4], [2, 2.2, 3, 5])
# t_score, p_value = ttest_ind([1,2,3,4], [2, 2.2, 3, 5], equal_var=False)
print(t_score, p_value)

# 데이터가 정규분포를 따르는지 검정? 간단하게 scipy.stats 모듈의 noramltest를 사용. (z검정)
 ## 주의할 점. 검정할 표본이 최소 8개, 적어도 20개는 넘어야 정확함.
import numpy as np
from scipy.stats import normaltest, sem
z_score, p_value = normaltest(np.random.binomial(1, 0.5, size=100))
print(z_score, p_value)

# sem (Standard Error of the Mean. 표준오차)을 이용해 신뢰구간에 붙는 +- 값을 구해볼 수 있음.
print(sem(np.random.binomial(1, 0.5, size=100)))

"""
# 베이지안 통계학
 매개변수를 추정하고 신뢰구간을 계산하는 전통적인 통계학과는 달리, 매개변수 간 의존관계를 가정함.
 이런 의존관계는 해당 분야의 지식에 근거, 데이터와 별도로 분석 과정에서 사람이 설정함.
 사전지식을 이용해 분석하기 전 부터 매개변수의 분포를 가정하고 데이터가 추가되면 이를 갱신.
 
베이즈 정리 P(T|D) = [P(T)*P(D|T) / P(D)]에서 T를 실제값, D를 주어진 데이터로 가정하고 계산. 실제 매개변수 T는 미지의 값이므로 확률 분포로 표현함.
 > 즉, P(T|D)는 데이터 D가 주어졌을 때 매개변수 T의 분포를 의미.
 > P(T) : 선험적 확률. 사전지식을 이용해 얻은 T의 분포
 > P(D|T) : 우도(likelihood) 확률. 특정 매개변수 T를 가정할 때 주어진 데이터가 발생할 확률
 > P(D) : 가능한 모든 매개변수를 가정할 때 주어진 데이터가 발생할 확률.
 
하지만, 데이터의 차원이 높아지면 P(D|T)를 구하는 것이 어려울 때가 자주 있음. 데이터가 많이 필요해짐. 이럴땐 나이브-베이즈를 이용. 데이터의 각 차원이 서로 독립이라 가정.
 > 따라서, P(D|T) = P(D1|T) * P(D2|T) * ... * P(Dd|T) 식이 성립.
 > 현실에선 대부분의 데이터가 적어도 조금씩 영향을 주고받으므로 가정 자체는 거의 항상 틀리지만, 결과적으로 성능은 잘 나오는 편.
 
또다른 절충안으론 베이지안 네트워크가 있음. 사전지식을 이용해 변수 간 상관관계를 정의함.
 > 변수의 관계를 직접 정의하고 나면 이에 해당하는 조건부확률만 모델링하면 됨. 상대적으로 계산이 간단해짐.
 > 일반적으로 해당 분야의 지식에 기반해 변수의 관계를 직접 정의함.
 
상황에 따라 선험적 확률 P(T)가 전혀 알려지지 않은 경우도 있음. 이땐 단순한 방법으로 선험적 확률을 추정해 적용함. (ex. 성별은 남녀가 50%의 확률로 존재한다고 가정)
 > 고차원적으로 보면, 엔트로피를 극대화화는 선험적 확률을 이용한다.
  >> 확률분포의 엔트로피는 분포의 무작위성을 나타내기 때문에, 엔트로피를 극대화 하는 것은 선험적 확률을 모르는 것과 같은 가정을 의미함.
"""