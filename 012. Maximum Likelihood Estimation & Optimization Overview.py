"""
확률모델은 보통 매개변수 theta 로 정의.(정규분포를 이용한다면 평균, 표준편차가 theta에 해당.)
P(X|theta)를 최대화 하는 매개변수 theta를 찾는것이 목표.
 > 최대우도추정(MLE)으로 최적화된 theta를 찾는 것을 '학습'이라고 함.
 
MLE의 일반적인 표현 : P(X | theta) = P(X_1 | theta) * P(X_2 | theta) * ... * P(X_N | theta)
 > 계산의 편의성을 위해 양변에 로그를 취하는데, P(X | theta)를 극대화하는 매개변수 log(P(X | theta)) 또한 극대화 함.
 > log(A*B) = log(A) + log(B)가 되는 특성을 사용한다면 식을 다르게 표현할 수 있음.
  >> log(P(X | theta)) = log(P(X_1 | theta)) + log(P(X_2 | theta)) + ... + log(P(X_N | theta))
  
최대우도추정은 학습데이터와 유사한 데이터엔 잘 작동하지만 다른 데이터에 일반화하기 어려운 과적합의 문제가 있음.
하지만 대안으로 제시된 베이지안 방법론은 훨씬 복잡하고 속도가 느릴 뿐더러, 현실적으로 사용하기 어려운 문제가 있어 최대우도추정을 사용함.
"""

"""
1. Curve Fitting Example
 > y가 정규분포 잡음이 섞인 일차함수라는 가정. 그러면 mx + b의 형태가 될 것.
 > 여기에 잡음을 고려하면 y의 pdf는 f(y) = exp[{(mx + b) - y}^2 / 2 * sigma^2]처럼 나타날 것. 목표는 매개변수 m, b, mu({(mx + b) - y}^2), sigma를 찾는 것.
  (전개 과정은 별도 정리 참고)
 > 로그우도 L을 전개 후, 이를 극대화 하는 값? 
  >> L은 m과 b의 이차함수로 표현되므로, L을 m과 b에 대해 미분한 식이 0이되는 지점이 L을 극대화 하는 지점.
 > 편미분 후 양번을 데이터 수 N으로 나누고 정리하면 식은 0 = m * x_bar + b + y_bar (x_bar, y_bar : 주어진 데이터에서의 x,y의 평균) 형태가 될 것.
 > 다시 정리하면 최소제곱법을 사용한 결과와 같아짐. 가정이 정확할 때에만. 가정이 다르다면 로그 우도함수의 형태가 바뀌고, 닫힌형태의 해가 존재하지 않으므로 별도 계산이 필요.
 
2. Logistig Regression Example
 > 정답 y가 베르누이 분포를 따르므로, y가 0, 1인 경우로 나눠서 생각.
  >> p(x)는 예측값이 1일 확률을 계산하므로, 1-p(x)가 예측값이 0이 될 확률인 셈.
"""

"""
* Optimization
 - 어떤 함수를 최소화(or 최대화)하는 값을 찾는 과정을 의미.
 - 일반적인 문제의 정의는 다음과 같음.
     theta가 d차원 벡터이고 함수 f(theta), g(thega)가 주어짐. 이때 g(theta) <= 0 을 만족하면서 f(theta)를 최소화하는 theta는?
 - 앞서 진행한 최대우도추정이 과적합에 취약함. 이런 과적합을 막기위해 매개변수에 특정 제약조건을 거는 방법을 주로 사용함.
  > L = [우도함수 식] - [lambda * (Sigma |w|)] --> [] 안의 식이 제약을 거는 것. 
   >> 절대값의 합을 제한하는 회귀를 Lasso 회귀라 함. (L1)
   >> 절대값 대신 제곱을 넣어 제한할 수 있음. 이 회귀를 Ridge 회귀라 함. (L2) 
   >> 이 둘을 합치면 Elastic 회귀라 함.
 - 보통 직접 계산하지 않고, 수치연산 라이브러리를 통해 해결.
  > 그런데 이래도 최적값을 찾지 못하는 경우가 발생.
   1) 학습을 반복해도 오차가 점점 증가. --> 초기값을 잘못 설정했을 때 발생. 임의의 다른값을 넣거나 초기값의 범위를 바꾸면 해결 가능.
   2) 오차가 감소해 값을 찾았지만 이 값이 최적값이 아님. --> 나름대로 최적화된 변수지만 가장 좋은 답이 아닌 경우. --> 경사하강법, 볼록최적화를 사용해서 해결.
    >> 경사하강법? 눈을 감고 산을 오르는 걸 생각하면 됨. 머신러닝때 배웠지만 다시한번 간단하게 짚고가자.
    >> 어떻게 해야 가장 빠르게 산 정상에 도착할까? '걸음의 방향'과 '보폭'에 달려있음.
     >>> 경사하강법은 걸음의 방향과 보폭을 계산하고 그에 따라 매개변수를 갱신하는 과정을 반복함.
     >>> 경사는 목적함수의 1차 미분. 2차 미분값인 헤시안(Hessian)을 사용. 보다 정확한 방향을 찾을 수 있지만 연산량이 훨씬 많음.
         (경사하강을 통해 어느정도 최적화를 진행한 후 헤시안을 적용해 세밀한 최적화를 하기도 함.) (보니깐 2차원 행렬형태로 확장한거인듯. 파고들기엔 좀 시간이 많이걸릴것같다.)
     >>> 경사는 단순히 x를 갱신할 방향만을 제시. 자동으로 보폭을 조절하는 알고리즘이 많이 있음.
         (보폭이 너무 작으면 비슷한 연산을 계속 수행해 비효율적. 보폭이 너무 크다면 목적함수가 증가하는 일이 발생.)
     >>> 경사와 보폭을 잘 잡아도 문제가 있음. 목적함수가 볼록함수 형태 (ex. y = x^2 형태. 아래로 볼록.)이면 지역 최소점으로 수렴할 수 있음.
    >> 볼록 최적화? 목적함수가 볼록함수(최소값이 1개)인 경우 최적화 방법을 이용해 최적해를 찾는 방법.
"""

"""
* Stochastic Gradient Descent
 - 일반적인 경사하강에선 데이터의 크기 N이 너무 크면 전체 데이터에서 경사를 구하는데 시간이 오래걸림.
 - 무작위로 추출하는 데이터 표본 하나에서 경사를 구하고 이를 기준으로 파라미터 theta를 갱신하는 경사하강법.
 - mini-batch SGD는 데이터 표본 하나가 아닌 여럭을 골라 평균 경사를 사용. 그래서 일반적인 SGD보다 안정적.
"""
